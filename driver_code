import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_curve, auc

class LogisticRegression:
    def __init__(self, lr=0.05, it=10):
        self.lr = lr
        self.it = it
        self.W = None
        self.losses = []

    def normalize_data(self, df):
        for col in df.columns[:-1]:
            df[col] = (df[col] - df[col].min()) / (df[col].max() - df[col].min())
        return df

    def sigmoid(self, x):
        return 1 / (1 + np.exp(-x))

    def log_regression(self, X, W):
        return self.sigmoid(np.dot(X, W))

    def loss_function(self, y_true, y_pred):
        eps = 1e-15
        y_pred = np.clip(y_pred, eps, 1 - eps)
        return -(y_true * (np.log(y_pred) + (1 - y_true) * (1 - np.log(1 - y_pred)))).mean()

    def gradient_descent(self, X, Y):
        n = len(Y)
        for i in range(self.it):
            y_pred = self.log_regression(X, self.W)
            loss = self.loss_function(Y, y_pred)
            self.losses.append(loss)

            grad = np.dot(X.T, (y_pred - Y)) / n
            self.W = self.W - self.lr * grad

    def fit(self, X_train, Y_train):
        att = X_train.shape[1]
        self.W = np.zeros(att)
        X_train = np.column_stack((np.ones(len(X_train)), X_train))
        self.gradient_descent(X_train, Y_train)

    def predict(self, X):
        X = np.column_stack((np.ones(len(X)), X))
        probs = self.log_regression(X, self.W)
        return (probs >= 0.5).astype(int)

    def evaluate_performance(self, Y_actual, Y_pred):
        tp = np.sum((Y_actual == 1) & (Y_pred == 1))
        tn = np.sum((Y_actual == 0) & (Y_pred == 0))
        fp = np.sum((Y_actual == 0) & (Y_pred == 1))
        fn = np.sum((Y_actual == 1) & (Y_pred == 0))

        sensitivity = tp / (tp + fn)
        specificity = tn / (tn + fp)
        precision = tp / (tp + fp)
        f_measure = 2 * precision * sensitivity / (sensitivity + precision)
        accuracy = (tp + tn) / (tp + tn + fp + fn)

        print('Accuracy:', accuracy)
        print('Sensitivity:', sensitivity)
        print('Specificity:', specificity)
        print('Precision:', precision)
        print('F_measure:', f_measure)

    def plot_roc_curve(self, Y_actual, Y_pred):
        fpr, tpr, _ = roc_curve(Y_actual, Y_pred)
        roc_auc = auc(fpr, tpr)

        plt.figure()
        plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc)
        plt.xlabel('False Positive Rate ->')
        plt.ylabel('True Positive Rate ->')
        plt.title('ROC Curve')
        plt.legend(loc='lower right')
        plt.show()

    def plot_decision_boundary(self, X, Y):
        x1_min, x1_max = X[:, 1].min() - 1, X[:, 1].max() + 1
        x2_min, x2_max = X[:, 2].min() - 1, X[:, 2].max() + 1
        xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, 0.01), np.arange(x2_min, x2_max, 0.01))

        Z = self.predict(np.c_[np.ones(xx1.ravel().shape[0]), xx1.ravel(), xx2.ravel()])
        Z = Z.reshape(xx1.shape)

        plt.contourf(xx1, xx2, Z, alpha=0.3)
        plt.scatter(X[Y == 0][:, 1], X[Y == 0][:, 2], label='Class 0', color='grey', edgecolors='k')
        plt.scatter(X[Y == 1][:, 1], X[Y == 1][:, 2], label='Class 1', color='black', edgecolors='k')
        plt.title('Decision Boundary Line')
        plt.xlabel('x1')
        plt.ylabel('x2')
        plt.legend()
        plt.show()

    def plot_logistic_function(self, X, Y):
        x = np.random.uniform(-10, 10, 1000)
        x.sort()
        y = 1 / (1 + np.exp(-x))

        Z = np.dot(X, self.W)
        y_pred = 1 / (1 + np.exp(-Z))

        plt.title('Logistic Function')
        plt.plot(x, y)
        plt.scatter(Z, y_pred, color='r')
        plt.xlabel('X ->')
        plt.ylabel('f(X) ->')
        plt.show()

# Data Preparation
df = pd.read_csv('/content/drive/MyDrive/DM/data2.csv')
column_names = ['x1', 'x2', 'x3', 'y']
df.columns = column_names

# Splitting the DataSet
X_train, X_test, Y_train, Y_test = train_test_split(df.iloc[:, :-1], df['y'], test_size=0.3)

# Create and use Logistic Regression model
logreg = LogisticRegression(lr=0.05, it=10)
df_normalized = logreg.normalize_data(pd.concat([X_train, Y_train], axis=1))
logreg.fit(df_normalized.iloc[:, :-1].values, df_normalized['y'].values)
Y_test_pred = logreg.predict(X_test.values)

# Evaluate performance
logreg.evaluate_performance(Y_test.values, Y_test_pred)

# Plot ROC Curve
logreg.plot_roc_curve(Y_test.values, Y_test_pred)

# Plot Decision Boundary
logreg.plot_decision_boundary(X_test.values, Y_test.values)

# Plot Logistic Function
logreg.plot_logistic_function(X_test.values, Y_test.values)

print('Values of the Parameters:', logreg.W)
